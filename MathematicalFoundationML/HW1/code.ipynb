{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero importemos las librerías que usaremos a lo largo del experimento, además de marcar que el solver no nos muestre el progreso, definir un tiempo límite para la ejecución de las funciones y una semilla para que los experimentos sean reproducibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import log, floor, sqrt\n",
    "from func_timeout import func_set_timeout, FunctionTimedOut\n",
    "\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "timelimit = 100\n",
    "semilla = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora consideremos una función que resuelve un problema cuadrático. Esta función fue obtenida del recurso entregado en el enunciado de la tarea. Para los problemas que estamos considerando esta función tiene errores numéricos cuando la solución no existe puesto que se empieza a ir a infinito antes de que la matriz KKT sea singular, por lo que en caso de fallar devolveremos que la solución no existe (lo implementaremos con una excepción)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver(P, q, G, h):\n",
    "    args = [cvxopt.matrix(P), cvxopt.matrix(q), cvxopt.matrix(G), cvxopt.matrix(h)]\n",
    "    try:\n",
    "        sol = cvxopt.solvers.qp(*args)\n",
    "        if 'optimal' not in sol['status']:\n",
    "            return None\n",
    "        return np.array(sol['x']).reshape((P.shape[1],))\n",
    "    except ValueError as e:\n",
    "        if \"domain error\" in str(e):\n",
    "            return None\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora consideremos crear una función que me divida los datos en datos de entrenamiento, de testeo y de validación según una proporción dada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(X, Y, train = 0.8, validate = 0.1, test = 0.1):\n",
    "    X_train, X_aux, Y_train, Y_aux = train_test_split(X, Y, train_size = train, random_state = semilla)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_aux, Y_aux, train_size = validate/(validate + test), random_state = semilla)\n",
    "    return X_train, X_val, X_test, Y_train, Y_val, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos una función que lea los datos en función del test a considerar y que además los preprocese agregando la columna adicional con unos para que el separador sea afín."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer(test):\n",
    "    X = np.load('datos_T1/data/test_' + str(test) + '/X.npy')\n",
    "    X = np.append(X, np.ones((X.shape[0], 1)), axis=1)\n",
    "    Y = np.load('datos_T1/data/test_' + str(test) + '/Y.npy')\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedamos a resolver el problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el problema (hard-SVM) notemos que $$\\lVert w \\rVert_2^2 = w^TIw$$ donde $I$ es la matriz identidad, por lo que el problema (hard-SVM) se puede escribir en forma cuadrática como \n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "&\\min_{w \\in \\mathbb{R}^d} \\frac{1}{2} w^TIw \\\\\n",
    "&\\text{s.a. } -Y_i\\sum_{j=1}^d X_{ij}\\cdot w_j \\leq -1 \\quad \\forall i \\in [n]\n",
    "\\end{aligned}\n",
    "\n",
    "Y para el formato descrito por el solver tenemos que $P = I$, $q = 0$, $G = XI(-Y_i)$, $h = -\\vec{1}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_set_timeout(timelimit)\n",
    "def hardSVMsolver(X, Y):\n",
    "    n, d = X.shape\n",
    "    P = np.eye(d, dtype = float)\n",
    "    q = np.zeros(d, dtype = float)\n",
    "    G = (X * (-Y[:, np.newaxis]))\n",
    "    h = np.full(n, -1, dtype = float)\n",
    "    w = solver(P, q, G, h)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el problema (soft-SVM) consideremos las primeras $d$ entradas del vector variable como $w$ y las siguientes $n$ entradas como $\\xi$. El problema (soft-SVM) se puede escribir en forma cuadrática como \n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "&\\min_{w \\in \\mathbb{R}^d} &\\frac{\\lambda}{2} w^TIw + \\sum_{i=1}^n \\xi_i &\\\\\n",
    "&\\text{s.a. } &-Y_i\\sum_{j=1}^d X_{ij}\\cdot w_j - \\xi_i \\leq -1 & \\ \\ \\forall i \\in [n] \\\\\n",
    "& & -\\xi_i \\leq 0 & \\ \\ \\forall i \\in [n]\n",
    "\\end{aligned}\n",
    "\n",
    "Y para el formato descrito por el solver tenemos que $P = \\binom{\\lambda \\cdot I_{d,d} \\ 0_{d,n}}{0_{n,d} \\ \\ \\ \\ \\ 0_{n,n}}$, $q = \\binom{0}{\\vec{1}_n}$, $G = \\binom{XI(-Y_i) \\ -I_n}{0_{n, d} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ -I_n}$, $h = \\binom{-\\vec{1}_n}{\\vec{0}_n}$.\n",
    "\n",
    "Además debemos separar los datos en datos de entrenamiento, datos de validación y datos de prueba, de tal forma de escoger el $\\lambda$ adecuado de forma algorítmica, para esto vamos a diseñar una rutina que separe los datos según una cierta proporción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y lo implementamos en conjunto con la búsqueda automática del $\\lambda$ óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softSVM(X, Y, Lambda):\n",
    "    n, d = X.shape\n",
    "    P = np.zeros((d+n, d+n), dtype = float)\n",
    "    P[:d, :d] = Lambda*np.eye(d, dtype = float)\n",
    "    \n",
    "    q = np.zeros(d+n, dtype = float)\n",
    "    q[d:] = 1.0\n",
    "    \n",
    "    G = np.zeros((2*n, d+n), dtype = float)\n",
    "    G[:n, :d] = -Y[:, np.newaxis] * X\n",
    "    G[:n, d:] = -np.eye(n)\n",
    "    G[n:, d:] = -np.eye(n)\n",
    "    \n",
    "    h = np.zeros(2*n, dtype = float)\n",
    "    h[:n] = -1.0\n",
    "    \n",
    "    return solver(P, q, G, h)[:d]\n",
    "\n",
    "@func_set_timeout(timelimit)\n",
    "def softSVMsolver(X, Y):\n",
    "    n, d = X.shape\n",
    "    X1, X2, X3, Y1, Y2, Y3 = splitter(X, Y)\n",
    "    best = n+1\n",
    "    wbest = np.zeros(d)\n",
    "    for exp in range(0, 11):\n",
    "        Lambda = 2**(-exp)\n",
    "        w = softSVM(X1, Y1, Lambda)\n",
    "        v = (Lambda/2.0)*np.dot(w, w) + sum(max(0.0, 1.0 - np.dot(w, X2[i])*Y2[i]) for i in range(len(X2)))\n",
    "        if v < best:\n",
    "            best = v\n",
    "            wbest = w\n",
    "    risk = 100*(sum(1 for i in range(len(X3)) if Y3[i] *np.dot(wbest, X3[i]) < 1))/len(X3)\n",
    "    return wbest, risk\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero veamos para cada caso de prueba si son linealmente separables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos resolviendo el caso 1 que tiene 100 datos y 20 características\n",
      "Se demoró 0.05 segundos y encontró un separador de margen 0.83\n",
      "\n",
      "Estamos resolviendo el caso 2 que tiene 800 datos y 100 características\n",
      "Se demoró 0.97 segundos y no existe un separador afín\n",
      "\n",
      "Estamos resolviendo el caso 3 que tiene 2000 datos y 300 características\n",
      "Se demoró 0.40 segundos y encontró un separador de margen 0.74\n",
      "\n",
      "Estamos resolviendo el caso 4 que tiene 3000 datos y 500 características\n",
      "Se demoró 3.97 segundos y no existe un separador afín\n",
      "\n",
      "Estamos resolviendo el caso 5 que tiene 5000 datos y 1000 características\n",
      "Se demoró 5.42 segundos y encontró un separador de margen 1.27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    print(f\"Estamos resolviendo el caso {i} que tiene {X.shape[0]} datos y {X.shape[1] - 1} características\")\n",
    "    tstart = time.time()\n",
    "    try:\n",
    "        w = hardSVMsolver(X, Y)\n",
    "        tfinish = time.time()\n",
    "        print(f\"Se demoró {(tfinish - tstart):.2f} segundos y \", end = '')\n",
    "        if w is None:\n",
    "            print(\"no existe un separador afín\")\n",
    "        else:\n",
    "            print(f\"encontró un separador de margen {(1/np.dot(w, w)):.2f}\")\n",
    "    except FunctionTimedOut:\n",
    "        print(f\"Se está demorando más de {timelimit} segundos así que abortaremos el cálculo\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que el algoritmo fue capaz de encontrar el óptimo muy rápido (menos de 6 segundos) y que los casos separables son el 1, 3 y 5. Este algoritmo fue capaz de resolver el caso con 5000 datos y 1000 características en unos 5 segundos, por lo que una extrapolación del tiempo usado (al ojo) es que sería capaz de resolver algo con 50000 datos y 3000 características en un tiempo razonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora resolvamos los casos de prueba con (Soft-SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos resolviendo el caso 1 que tiene 100 datos y 20 características\n",
      "Se demoró 1.11 segundos y encontró un separador de margen 1.75 y en los datos de testing acertó un 50.0%\n",
      "\n",
      "Estamos resolviendo el caso 2 que tiene 800 datos y 100 características\n",
      "Se demoró 12.50 segundos y encontró un separador de margen 4.54 y en los datos de testing acertó un 41.25%\n",
      "\n",
      "Estamos resolviendo el caso 3 que tiene 2000 datos y 300 características\n",
      "Se está demorando más de 100 segundos así que abortaremos el cálculo\n",
      "\n",
      "Estamos resolviendo el caso 4 que tiene 3000 datos y 500 características\n",
      "Se está demorando más de 100 segundos así que abortaremos el cálculo\n",
      "\n",
      "Estamos resolviendo el caso 5 que tiene 5000 datos y 1000 características\n",
      "Se está demorando más de 100 segundos así que abortaremos el cálculo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    print(f\"Estamos resolviendo el caso {i} que tiene {X.shape[0]} datos y {X.shape[1] - 1} características\")\n",
    "    tstart = time.time()\n",
    "    try:\n",
    "        w, risk = softSVMsolver(X, Y)\n",
    "        tfinish = time.time()\n",
    "        print(f\"Se demoró {(tfinish - tstart):.2f} segundos y \", end = '')\n",
    "        print(f\"encontró un separador de margen {(1/np.dot(w, w)):.2f} y en los datos de testing acertó un {risk}%\")\n",
    "    except FunctionTimedOut:\n",
    "        print(f\"Se está demorando más de {timelimit} segundos así que abortaremos el cálculo\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obviamente siempre va a encontrar un separador (aunque sea uno muy malo). Notemos que acierta bastante poco en los casos que no ha visto, pero se debe en una parte a la naturaleza de los datos y en otra muy grande a la forma en que se escoje el $\\lambda$ óptimo (de la cual no estoy muy de acuerdo pero prefiero seguir el enunciado). Notemos que los 2 primeros casos anduvieron bien en tiempo, pero el tercero se demoró más de 100 segundos, por lo que se espera que este algoritmo sea capaz de encontrar el óptimo para un conjunto de unos 1000 datos y 150 características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora preprocesemos los datos con una matriz aleatoria tal como el algoritmo que diseñamos en la pregunta 4 y veamos la capacidad de dicho algoritmo de encontrar un separador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WinRateLowDim(X, Y, k, tries):\n",
    "    success = 0\n",
    "    for _ in range(tries):\n",
    "        A = np.random.randn(k, X.shape[1])\n",
    "        newX = (1.0/sqrt(k))*np.dot(X, A.T)\n",
    "        w = hardSVMsolver(newX, Y)\n",
    "        if w is not None:\n",
    "            success += 1\n",
    "    return 100*success/tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el caso 1 hay 100 datos y reduciremos la dimensión de los datos de 21 a 242\n",
      "Pudimos separar para el 100.0% de las matrices\n",
      "\n",
      "En el caso 2 hay 800 datos y reduciremos la dimensión de los datos de 101 a 326\n",
      "Pudimos separar para el 0.0% de las matrices\n",
      "\n",
      "En el caso 3 hay 2000 datos y reduciremos la dimensión de los datos de 301 a 363\n",
      "Pudimos separar para el 100.0% de las matrices\n",
      "\n",
      "En el caso 4 hay 3000 datos y reduciremos la dimensión de los datos de 501 a 380\n",
      "Pudimos separar para el 0.0% de las matrices\n",
      "\n",
      "En el caso 5 hay 5000 datos y reduciremos la dimensión de los datos de 1001 a 401\n",
      "Pudimos separar para el 0.0% de las matrices\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    k = floor(81*log(16*X.shape[0]**2)/4)\n",
    "    print(f\"En el caso {i} hay {X.shape[0]} datos y reduciremos la dimensión de los datos de {X.shape[1]} a {k}\")\n",
    "    try:\n",
    "        print(f\"Pudimos separar para el {WinRateLowDim(X, Y, k, 10)}% de las matrices\")\n",
    "    except FunctionTimedOut:\n",
    "        print(\"Las iteraciones se están demorando demasiado, así que abortamos el cálculo\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso 1 y 3 las matrices eran separables y el 100% encontró separadores, sin embargo el caso 5 también era separable y no logró encontrar un separador nunca. En los casos no separables siguió sin poder encontrar un separador. Sin embargo la cota obtenida en la pregunta 4 es asintóticamente logarítmica pero tiene unas constantes muy grandes y además depende de $n$ que es el número de datos y no del $k$ que es la dimensión de los datos, por lo que si observamos bien hay casos en los que la \"reducción\" de dimensionalidad hace la dimensionalidad más grande. Veamos que ocurre si definimos una reducción proporcional a $k$ de la dimensionalidad, probemos con $0.8$ de la dimensión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el caso 1 hay 100 datos y reduciremos la dimensión de los datos de 21 a 16\n",
      "Pudimos separar para el 10.0% de las matrices\n",
      "\n",
      "En el caso 2 hay 800 datos y reduciremos la dimensión de los datos de 101 a 80\n",
      "Pudimos separar para el 0.0% de las matrices\n",
      "\n",
      "En el caso 3 hay 2000 datos y reduciremos la dimensión de los datos de 301 a 240\n",
      "Pudimos separar para el 0.0% de las matrices\n",
      "\n",
      "En el caso 4 hay 3000 datos y reduciremos la dimensión de los datos de 501 a 400\n",
      "Pudimos separar para el 0.0% de las matrices\n",
      "\n",
      "En el caso 5 hay 5000 datos y reduciremos la dimensión de los datos de 1001 a 800\n",
      "Pudimos separar para el 0.0% de las matrices\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    k = floor(0.8*X.shape[1])\n",
    "    print(f\"En el caso {i} hay {X.shape[0]} datos y reduciremos la dimensión de los datos de {X.shape[1]} a {k}\")\n",
    "    try:\n",
    "        print(f\"Pudimos separar para el {WinRateLowDim(X, Y, k, 10)}% de las matrices\")\n",
    "    except FunctionTimedOut:\n",
    "        print(\"Las iteraciones se están demorando demasiado, así que abortamos el cálculo\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se puede ver que pese a que la reducción de la dimensión no fue mucha, casi nunca era capaz de encontrar un separador. Quizás si el tiempo se reduce en lo suficiente como para probar demasiadas matrices distintas podría llegar a ser conveniente, ¡veámoslo!\n",
    "\n",
    "Estudiaremos los tiempos de ejecución tanto para (Hard-SVM) como para (Soft-SVM), y para el $k$ obtenido en la pregunta 4 y para el $k$ proporcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el caso 1 hay 100 datos y reduciremos la dimensión de los datos de 21 a 242\n",
      "Se demoró 0.07 segundos\n",
      "\n",
      "En el caso 2 hay 800 datos y reduciremos la dimensión de los datos de 101 a 326\n",
      "Se demoró 0.09 segundos\n",
      "\n",
      "En el caso 3 hay 2000 datos y reduciremos la dimensión de los datos de 301 a 363\n",
      "Se demoró 0.23 segundos\n",
      "\n",
      "En el caso 4 hay 3000 datos y reduciremos la dimensión de los datos de 501 a 380\n",
      "Se demoró 1.71 segundos\n",
      "\n",
      "En el caso 5 hay 5000 datos y reduciremos la dimensión de los datos de 1001 a 401\n",
      "Se demoró 1.19 segundos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    k = floor(81*log(16*X.shape[0]**2)/4)\n",
    "    A = np.random.randn(k, X.shape[1])\n",
    "    newX = (1.0/sqrt(k))*np.dot(X, A.T)\n",
    "    print(f\"En el caso {i} hay {X.shape[0]} datos y reduciremos la dimensión de los datos de {X.shape[1]} a {k}\")\n",
    "    try:\n",
    "        tstart = time.time()\n",
    "        w = hardSVMsolver(newX, Y)\n",
    "        tfinish = time.time()\n",
    "        print(f\"Se demoró {(tfinish - tstart):.2f} segundos\")\n",
    "    except FunctionTimedOut:\n",
    "        print(f\"Se demoró más de {timelimit} segundos\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el caso 1 hay 100 datos y reduciremos la dimensión de los datos de 21 a 16\n",
      "Se demoró 0.09 segundos\n",
      "\n",
      "En el caso 2 hay 800 datos y reduciremos la dimensión de los datos de 101 a 80\n",
      "Se demoró 0.19 segundos\n",
      "\n",
      "En el caso 3 hay 2000 datos y reduciremos la dimensión de los datos de 301 a 240\n",
      "Se demoró 0.91 segundos\n",
      "\n",
      "En el caso 4 hay 3000 datos y reduciremos la dimensión de los datos de 501 a 400\n",
      "Se demoró 0.92 segundos\n",
      "\n",
      "En el caso 5 hay 5000 datos y reduciremos la dimensión de los datos de 1001 a 800\n",
      "Se demoró 5.57 segundos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    k = floor(0.8*X.shape[1])\n",
    "    A = np.random.randn(k, X.shape[1])\n",
    "    newX = (1.0/sqrt(k))*np.dot(X, A.T)\n",
    "    print(f\"En el caso {i} hay {X.shape[0]} datos y reduciremos la dimensión de los datos de {X.shape[1]} a {k}\")\n",
    "    try:\n",
    "        tstart = time.time()\n",
    "        w = hardSVMsolver(newX, Y)\n",
    "        tfinish = time.time()\n",
    "        print(f\"Se demoró {(tfinish - tstart):.2f} segundos\")\n",
    "    except FunctionTimedOut:\n",
    "        print(f\"Se demoró más de {timelimit} segundos\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el caso 1 hay 100 datos y reduciremos la dimensión de los datos de 21 a 242\n",
      "Se demoró 0.84 segundos\n",
      "\n",
      "En el caso 2 hay 800 datos y reduciremos la dimensión de los datos de 101 a 326\n",
      "Se demoró 8.91 segundos\n",
      "\n",
      "En el caso 3 hay 2000 datos y reduciremos la dimensión de los datos de 301 a 363\n",
      "Se demoró 77.80 segundos\n",
      "\n",
      "En el caso 4 hay 3000 datos y reduciremos la dimensión de los datos de 501 a 380\n",
      "Se demoró más de 100 segundos\n",
      "\n",
      "En el caso 5 hay 5000 datos y reduciremos la dimensión de los datos de 1001 a 401\n",
      "Se demoró más de 100 segundos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    k = floor(81*log(16*X.shape[0]**2)/4)\n",
    "    A = np.random.randn(k, X.shape[1])\n",
    "    newX = (1.0/sqrt(k))*np.dot(X, A.T)\n",
    "    print(f\"En el caso {i} hay {X.shape[0]} datos y reduciremos la dimensión de los datos de {X.shape[1]} a {k}\")\n",
    "    try:\n",
    "        tstart = time.time()\n",
    "        w = softSVMsolver(newX, Y)\n",
    "        tfinish = time.time()\n",
    "        print(f\"Se demoró {(tfinish - tstart):.2f} segundos\")\n",
    "    except FunctionTimedOut:\n",
    "        print(f\"Se demoró más de {timelimit} segundos\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el caso 1 hay 100 datos y reduciremos la dimensión de los datos de 21 a 16\n",
      "Se demoró 0.58 segundos\n",
      "\n",
      "En el caso 2 hay 800 datos y reduciremos la dimensión de los datos de 101 a 80\n",
      "Se demoró 6.65 segundos\n",
      "\n",
      "En el caso 3 hay 2000 datos y reduciremos la dimensión de los datos de 301 a 240\n",
      "Se demoró 68.32 segundos\n",
      "\n",
      "En el caso 4 hay 3000 datos y reduciremos la dimensión de los datos de 501 a 400\n",
      "Se demoró más de 100 segundos\n",
      "\n",
      "En el caso 5 hay 5000 datos y reduciremos la dimensión de los datos de 1001 a 800\n",
      "Se demoró más de 100 segundos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    k = floor(0.8*X.shape[1])\n",
    "    A = np.random.randn(k, X.shape[1])\n",
    "    newX = (1.0/sqrt(k))*np.dot(X, A.T)\n",
    "    print(f\"En el caso {i} hay {X.shape[0]} datos y reduciremos la dimensión de los datos de {X.shape[1]} a {k}\")\n",
    "    try:\n",
    "        tstart = time.time()\n",
    "        w = softSVMsolver(newX, Y)\n",
    "        tfinish = time.time()\n",
    "        print(f\"Se demoró {(tfinish - tstart):.2f} segundos\")\n",
    "    except FunctionTimedOut:\n",
    "        print(f\"Se demoró más de {timelimit} segundos\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hay una ganancia de velocidad, puesto que ahora el caso número 3 si es capaz de correr para la versión (Soft-SVM) y basta ver cada ejemplo para notar la mejora en la velocidad. Sin embargo, la mejora de la velocidad es de aproximadamente al doble y no es suficiente para compensar que hay que probar al menos unas 10 matrices diferentes para recién ser capaces de obtener una respuesta. En este sentido, la verdad es que no ganamos nada y considero que es incluso más lento que el anterior el algoritmo y que nos serviría para conjuntos de 10 veces menos tamaño en ambos lados que el anterior.\n",
    "\n",
    "Un punto importante a considerar es que desconozco como fueron obtenidos los datos. Quizás en casos donde los datos tienen correlación esta idea de reducción de la dimensionalidad pueda tener más ventajas. Se me ocurre que por ejemplo en una base de datos de salud, puedes juntar ciertos datos en uno solo ya que son muy correlacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el dual de (Hard-SVM) tenemos que\n",
    "\\begin{aligned}\n",
    "\\max_{\\alpha \\in \\mathbb{R}^n} \\quad & \\sum_{i=1}^n \\alpha_i - \\frac{1}{2} \\sum_{i=1}^n \\sum_{k=1}^n \\alpha_i \\alpha_k y_i y_k \\langle x_i, x_k \\rangle \\\\\n",
    "\\text{s.t:} \\quad & \\alpha_i \\geq 0 \\quad \\forall i\\in[n]\n",
    "\\end{aligned}\n",
    "\n",
    "Por lo que se tiene que $P = (Y_iY_k \\langle X_i, X_k \\rangle)_{i,k\\in[n]}$, $q = \\vec{1}_d$, $G = -I_n$, $h = \\vec{0}_d$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_set_timeout(timelimit)\n",
    "def dualhardSVMsolver(X, Y):\n",
    "    n, d = X.shape\n",
    "    P = (np.dot(X, X.T)*Y[:, np.newaxis])*Y[np.newaxis, :]\n",
    "    q = -np.ones(n, dtype = float)\n",
    "    G = -np.eye(n, dtype = float)\n",
    "    h = np.zeros(n, dtype = float)\n",
    "    alpha = solver(P, q, G, h)\n",
    "    if alpha is None:\n",
    "        return None\n",
    "    w = np.sum(alpha[:, np.newaxis] * Y[:, np.newaxis] * X, axis = 0)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probemos nuestra implementación del dual de (Hard-SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos resolviendo el caso 1 que tiene 100 datos y 20 características\n",
      "Se demoró 0.05 segundos y encontró un separador de margen 0.83\n",
      "\n",
      "Estamos resolviendo el caso 2 que tiene 800 datos y 100 características\n",
      "Se demoró 0.35 segundos y no existe un separador afín\n",
      "\n",
      "Estamos resolviendo el caso 3 que tiene 2000 datos y 300 características\n",
      "Se demoró 4.31 segundos y encontró un separador de margen 0.74\n",
      "\n",
      "Estamos resolviendo el caso 4 que tiene 3000 datos y 500 características\n",
      "Se demoró 16.82 segundos y no existe un separador afín\n",
      "\n",
      "Estamos resolviendo el caso 5 que tiene 5000 datos y 1000 características\n",
      "Se demoró 50.15 segundos y encontró un separador de margen 1.27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    print(f\"Estamos resolviendo el caso {i} que tiene {X.shape[0]} datos y {X.shape[1] - 1} características\")\n",
    "    tstart = time.time()\n",
    "    try:\n",
    "        w = dualhardSVMsolver(X, Y)\n",
    "        tfinish = time.time()\n",
    "        print(f\"Se demoró {(tfinish - tstart):.2f} segundos y \", end = '')\n",
    "        if w is None:\n",
    "            print(\"no existe un separador afín\")\n",
    "        else:\n",
    "            print(f\"encontró un separador de margen {(1/np.dot(w, w)):.2f}\")\n",
    "    except FunctionTimedOut:\n",
    "        print(f\"Se está demorando más de {timelimit} segundos así que abortaremos el cálculo\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperarse obtuvo los mismos resultados. Sin embargo, la implementación sobre el dual de (Hard-SVM) fue bastante más lenta que la del primal de (Hard-SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el dual de (Soft-SVM) comencemos desde el problema primal\n",
    "\\begin{aligned}\n",
    "&\\min_{w \\in \\mathbb{R}^d} &\\frac{\\lambda}{2} \\lVert w \\rVert_2^2+ \\sum_{i=1}^n \\xi_i &\\\\\n",
    "&\\text{s.a. } &-Y_i\\langle X_i, w \\rangle \\leq \\xi_i - 1 & \\ \\ \\forall i \\in [n] \\\\\n",
    "& & -\\xi_i \\leq 0 & \\ \\ \\forall i \\in [n]\n",
    "\\end{aligned}\n",
    "\n",
    "Escribamos el langrangeano de esta función\n",
    "\n",
    "$$\\mathcal{L}(w, \\xi, \\alpha, \\beta) = \\frac{\\lambda}{2} \\lVert w \\rVert_2^2+ \\sum_{i=1}^n \\xi_i + \\sum_{i=1}^n \\alpha_i(1 - Y_i\\langle X_i, w\\rangle - \\xi_i) + \\sum_{i=1}^n\\beta_i(-\\xi_i)$$\n",
    "\n",
    "Simplificando un poco\n",
    "$$\\mathcal{L}(w, \\xi, \\alpha, \\beta) = \\frac{\\lambda}{2} \\lVert w \\rVert_2^2 + \\sum_{i=1}^n \\alpha_i - \\sum_{i=1}^n \\alpha_i Y_i\\langle X_i, w\\rangle + \\sum_{i=1}^n \\xi_i(1 - \\alpha_i - \\beta_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que $\\frac{\\partial \\mathcal{L}}{\\partial w} = \\lambda w - \\sum_{i=1}^n\\alpha_iX_iY_i$. Al igualarlo a cero para encontrar el óptimo obtenemos la relación\n",
    "\n",
    "$$w = \\frac{1}{\\lambda}\\sum_{i=1}^n\\alpha_iX_iY_i$$\n",
    "\n",
    "Tenemos que $\\frac{\\partial \\mathcal{L}}{\\partial \\xi} = \\vec{1} - \\alpha - \\beta$. Al igualarlo a cero para encontrar el óptimo obtenemos la relación\n",
    "\n",
    "$$\\vec{1} - \\alpha = \\beta$$\n",
    "\n",
    "Reemplazando estos valores en el langrangeano obtenemos que en el óptimo nos interesa estudiar la función\n",
    "$$\\mathcal{L} = \\frac{\\lambda}{2} \\lVert \\frac{1}{\\lambda}\\sum_{i=1}^n\\alpha_iX_iY_i \\rVert_2^2  + \\sum_{i=1}^n \\alpha_i - \\sum_{i=1}^n \\alpha_i Y_i\\langle X_i, \\frac{1}{\\lambda}\\sum_{i=1}^n\\alpha_iX_iY_i\\rangle + \\sum_{i=1}^n \\xi_i(1 - \\alpha_i - (1 - \\alpha_i))$$\n",
    "$$\\mathcal{L} = \\sum_{i=1}^n \\alpha_i + \\frac{1}{2\\lambda} \\sum_{i=1}^n\\sum_{k=1}^n \\alpha_i \\alpha_k Y_i Y_k \\langle X_i, X_k \\rangle - \\frac{1}{\\lambda} \\sum_{i=1}^n\\sum_{k=1}^n \\alpha_i \\alpha_k Y_i Y_k \\langle X_i, X_k \\rangle$$\n",
    "$$\\mathcal{L} = \\sum_{i=1}^n \\alpha_i - \\frac{1}{2\\lambda} \\sum_{i=1}^n\\sum_{k=1}^n \\alpha_i \\alpha_k Y_i Y_k \\langle X_i, X_k \\rangle$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero recordemos que además impusimos la restricción\n",
    "$$1 - \\alpha_i = \\beta_i$$\n",
    "Pero como $\\beta_i$ no aparece en ningún otro lugar, podemos hacer que tome cualquier valor mayor o igual a cero, de lo que se concluye que\n",
    "$$1 - \\alpha_i \\geq 0 \\rightarrow \\alpha_i \\leq 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que el dual de (Soft-SVM) corresponde a\n",
    "\\begin{aligned}\n",
    "\\max_{\\alpha \\in \\mathbb{R}^n} \\quad & \\sum_{i=1}^n \\alpha_i - \\frac{1}{2\\lambda} \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j \\langle x_i, x_j \\rangle \\\\\n",
    "\\text{s.t.} \\quad & 0 \\leq \\alpha_i \\leq 1, \\quad \\forall i \\in [n], \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Implementémoslo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dualsoftSVM(X, Y, Lambda):\n",
    "    n, d = X.shape\n",
    "    P = (1/Lambda)*(np.dot(X, X.T)*Y[:, np.newaxis])*Y[np.newaxis, :]\n",
    "    q = -np.ones(n, dtype = float)\n",
    "    G = np.zeros((2*n, n), dtype = float)\n",
    "    G[:n, :n] = -np.eye(n, dtype = float)\n",
    "    G[n:2*n, :n] = np.eye(n, dtype = float)\n",
    "    h = np.zeros(2*n, dtype = float)\n",
    "    h[n:2*n] = np.ones(n, dtype = float)\n",
    "    alpha = solver(P, q, G, h)\n",
    "    w = (1/Lambda)*np.sum(alpha[:, np.newaxis] * Y[:, np.newaxis] * X, axis = 0)\n",
    "    return w\n",
    "\n",
    "@func_set_timeout(timelimit)\n",
    "def dualsoftSVMsolver(X, Y):\n",
    "    n, d = X.shape\n",
    "    X1, X2, X3, Y1, Y2, Y3 = splitter(X, Y)\n",
    "    best = n+1\n",
    "    wbest = np.zeros(d)\n",
    "    for exp in range(0, 11):\n",
    "        Lambda = 2**(-exp)\n",
    "        w = dualsoftSVM(X1, Y1, Lambda)\n",
    "        v = (Lambda/2.0)*np.dot(w, w) + sum(max(0.0, 1.0 - np.dot(w, X2[i])*Y2[i]) for i in range(len(X2)))\n",
    "        if v < best:\n",
    "            best = v\n",
    "            wbest = w\n",
    "    risk = 100*(sum(1 for i in range(len(X3)) if Y3[i] *np.dot(wbest, X3[i]) < 1))/len(X3)\n",
    "    return wbest, risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y finalmente probemos nuestra implementación del dual de (Soft-SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos resolviendo el caso 1 que tiene 100 datos y 20 características\n",
      "Se demoró 0.49 segundos y encontró un separador de margen 1.75 y en los datos de testing acertó un 50.0%\n",
      "\n",
      "Estamos resolviendo el caso 2 que tiene 800 datos y 100 características\n",
      "Se demoró 5.60 segundos y encontró un separador de margen 4.54 y en los datos de testing acertó un 41.25%\n",
      "\n",
      "Estamos resolviendo el caso 3 que tiene 2000 datos y 300 características\n",
      "Se demoró 55.01 segundos y encontró un separador de margen 1.14 y en los datos de testing acertó un 18.5%\n",
      "\n",
      "Estamos resolviendo el caso 4 que tiene 3000 datos y 500 características\n",
      "Se está demorando más de 100 segundos así que abortaremos el cálculo\n",
      "\n",
      "Estamos resolviendo el caso 5 que tiene 5000 datos y 1000 características\n",
      "Se está demorando más de 100 segundos así que abortaremos el cálculo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    X, Y = leer(i)\n",
    "    print(f\"Estamos resolviendo el caso {i} que tiene {X.shape[0]} datos y {X.shape[1] - 1} características\")\n",
    "    tstart = time.time()\n",
    "    try:\n",
    "        w, risk = dualsoftSVMsolver(X, Y)\n",
    "        tfinish = time.time()\n",
    "        print(f\"Se demoró {(tfinish - tstart):.2f} segundos y \", end = '')\n",
    "        print(f\"encontró un separador de margen {(1/np.dot(w, w)):.2f} y en los datos de testing acertó un {risk}%\")\n",
    "    except FunctionTimedOut:\n",
    "        print(f\"Se está demorando más de {timelimit} segundos así que abortaremos el cálculo\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el (Soft-SVM) podemos observar que la implementación del dual fue bastante más rápido, siendo cercano al doble más rápido que la implementación del algoritmo del primal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
